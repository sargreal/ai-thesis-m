\section{Approach}\label{sec:approach}

% Problem definition

We formulate the planning problem in the domain ``Overcooked'' as a temporal HTN planning problem in the language ANML in Section \ref{sec:approach-domain}.
We rely on acting to be able to respond to tasks that are received after the beginning of execution.
The architecture for acting in FAPE \cite{bit-monnotTemporalHierarchicalModels2016a} is extended to handle this stream of tasks (see Section \ref{sec:approach-acting}).

The particular problem to solve is that the received tasks have associated deadlines, that may prove impossible to achieve.
The goal is to optimize the current plans, such that the new tasks can be inserted successfully.
We consider two options for solving this optimization problem:

\begin{enumerate}
    \item In Section \ref{sec:approach-robustness} we introduce a heuristic for the robustness of a plan. This is expected to increase the ability to insert a new task at a later time point
    \item In Section \ref{sec:approach-preparation} we then introduce a preparation algorithm that uses the hierarchical domain definition to determine which tasks can be prepared given a set of possible tasks that may be received.
\end{enumerate}

\subsection{Domain Definition}
\label{sec:approach-domain}

\subsection{Acting and Online Planning with a Stream of Tasks}
\label{sec:approach-acting}

The core element around which this thesis is built is that tasks may be received during the execution of a plan, so during the acting phase.
This has been considered in RAE \citep{ghallabAutomatedPlanningActing2016}, but has not been implemented in the FAPE planner \citep{bit-monnotTemporalHierarchicalModels2016a}.
We extend the theoretical Actor Model in FAPE (see Figure \ref{fig:background-acting-fape}) with a task stream connecting the Activity Manager to other actors or users (see Figure \ref{fig:approach-acting-architecture}).
Technically this interaction exists in FAPE already through the message $newgoal(g)$, but was not made explicit in the architecture.


\bild{fig:approach-acting-architecture}{architecture}{Architecture of FAPE with a Stream of Tasks}{12}

The interactions between the components are implemented as in FAPE using message passing, with each component being a state machine.
The observation database and the execution of skills are not considered in this work, as no interaction with a platform was introduced.
For more details on that see \cite{bit-monnotTemporalHierarchicalModels2016a}.

\subsubsection{Stream of Tasks}

Each task that is managed by the Activity Manager is received through the stream of tasks.
A task in this stream has an optional deadline $t_{deadline}$ and is received by the Activity Manager at a specific time $t_{receive}$.
The task is a temporally qualified ground task $\langle[t_{receive},t_{deadline}] \tau(r_1,\dots,r_n)\rangle$.
If no deadline is specified, it is $max(\mathbb{N})$.
Specifically, the task is sent to the Activity Manager using the message $newtask(t)$.

\subsubsection{Activity Manager}

The Activity Manager is the core component of this model, managing all interactions between the other components.
It is a state machine with the states IDLE, WAITING\_FOR\_PLAN and DISPATCHING.
In the idle state, it is waiting for tasks to be submitted.
This is also the initial state.
It switches from the idle state to the planning state when receiving a task.
A planning request is sent to the Planner component, and the activity manager waits until a plan has been found.
Once a plan has been found, the state switches to dispatching, where the plan is continuously dispatched to the available skills.
When the plan has been fully executed, the state switches back to idle.

The messages that are available to the Activity Manager are as follows:
\begin{itemize}
    \item Incoming:
    \begin{itemize}
        \item $newtask(t)$: A new task that should be executed. 
        \item $newplan(\phi)$: A new plan is received from the planner.
        \item $noplan$: Planning failed.
        \item $dispatchsuccess(a)$ An action instance was successfully executed.
    \end{itemize}
    \item Outgoing:
    \begin{itemize}
        \item $planrequest(\phi)$: A request sent to the planner to search for a solution of $\phi$.
        \item $dispatch(a)$: Dispatch an action instance a.
    \end{itemize}
\end{itemize}

With these messages, the state machine of the Activity Manager is defined as follows.
A visual representation of the state machine is shown in Figure \ref{fig:approach-activity-manager}.

\begin{itemize}
    \item IDLE
    \begin{itemize}
        \item receive $newtask(t)$:
        \begin{enumerate}
            \item integrate $t$ into current plan $\phi$
            \item send $planrequest(\phi)$
            \item switch state to WAITING\_FOR\_PLAN
        \end{enumerate}
        % \item receive $dispatchsuccess(a)$:
        % \begin{enumerate}
        %     \item mark $a$ as executed
        %     \item stay in state IDLE
        % \end{enumerate}
    \end{itemize}
    \item WAITING\_FOR\_PLAN
    \begin{itemize}
        \item receive $newplan(\phi)$:
        \begin{enumerate}
            \item verify that $\phi$ corresponds to latest plan request sent
            \item switch state to DISPATCHING
        \end{enumerate}
        \item receive $noplan$:
        \begin{enumerate}
            \item shutdown
        \end{enumerate}
        \item receive $newtask(t)$:
        \begin{enumerate}
            \item integrate $t$ into current plan $\phi$
            \item send $planrequest(\phi)$
            \item stay in state WAITING\_FOR\_PLAN
        \end{enumerate}
        \item receive $dispatchsuccess(a)$:
        \begin{enumerate}
            \item mark $a$ as executed
            \item stay in state WAITING\_FOR\_PLAN
        \end{enumerate}
    \end{itemize}
    \item DISPATCHING
    \begin{enumerate}
        \item for all actions $a$ that can be executed 
        \begin{enumerate}
            \item send $dispatch(a)$
            \item mark $a$ as executing
        \end{enumerate} 
        \item if all actions executed: switch to state IDLE
    \end{enumerate}
    \begin{itemize}
        \item receive $dispatchsuccess(a)$:
        \begin{enumerate}
            \item mark $a$ as executed
            \item stay in state DISPATCHING
        \end{enumerate}
        \item receive $newtask(t)$:
        \begin{enumerate}
            \item integrate $t$ into current plan $\phi$
            \item send $planrequest(\phi)$
            \item switch state to WAITING\_FOR\_PLAN
        \end{enumerate}
    \end{itemize}
\end{itemize}

\bild{fig:approach-activity-manager}{state_activity_manager}{State machine diagram of the Activity Manager component}{10}

% The receiving of new tasks may occur at any point during the execution, so there are 3 separate points where this may happen.
% \begin{enumerate}
%     \item When the Acting Engine is in an idle state, the received task is added to the Planning Problem and Planning is started.
%     \item When the Acting Engine is currently planning, the current planning is stopped, the task is added to the Problem and planning is restarted.
%     \item When the Acting Engine is currently dispatching, the dispatching of new actions is stopped, the new task is added to the Problem, Planning is restarted and currently executing actions are finished while planning.
% \end{enumerate}

The insertion of a new task $t = \langle[t_{receive},t_{deadline}] \tau\rangle$ is handled by the plan modification Task Addition:

\begin{definition}[Task Addition]
    A chronicle $\phi_1 = (\pi_1,\mathcal{F}_1,\mathcal{C}_1)$ can be extended to a chronicle $\phi_2 = (\pi_2,\mathcal{F}_2,\mathcal{C}_2)$ by inserting a new temporally qualified task instance $t = \langle[t_{receive},t_{deadline}] \tau\rangle$. This transformation is denoted $\phi_1 \xrightarrow{t}_I \phi_2$ and does the following modifications to $\phi_2$
  \begin{align*}
    \pi_2 \leftarrow & \pi_1 \cup \{\tau\} \\
    \mathcal{F}_2 \leftarrow & \mathcal{F}_1 \cup \{t\} \\
    \mathcal{C}_2 \leftarrow & \mathcal{C}_1 \\
  \end{align*}
\end{definition}

\subsubsection{Planner Component}

The planner component executes the planning algorithm, and on failure tries first repairing and then replanning.
The planner uses the following messages:

\begin{itemize}
    \item Incoming:
    \begin{itemize}
        \item $planrequest(\phi)$: A request to search for a solution of $\phi$.
    \end{itemize}
    \item Outgoing:
    \begin{itemize}
        \item $newplan(\phi)$: Send a plan that is a solution back to the Activity Manager.
        \item $noplan$: Indicate to the Activity Manager that no plan exists.
    \end{itemize}
\end{itemize}

The planner has only 2 different states, IDLE and PLANNING.
If it receives a new $planrequest(\phi)$, it initiates a search asynchronously and moves to the PLANNING state.
In the PLANNING state it waits for the search to complete.
If a search finishes successfully, the planner sends a $newplan(\phi)$ message.
If the search fails, the planner issues a repair search and stays in the PLANNING state.
If the repair search fails as well, the planner issues a replanning search and stays in the PLANNING state.
If replanning fails as well, the planner sends a $noplan$ message.
If the planner receives a new $planrequest(\phi)$ in the PLANNING state, any running search is canceled and a new search for the new request is started asynchronously.

\subsubsection{Skills Component}

We do not implement skills in the context of this work but introduce the basics as a reference.
A skill breaks down the abstract definition of an action into direct manipulations of the environment.
As such, skills are inherently specific to the planning domain.
In the ``Overcooked'' domain, this results in 4 basic manipulations, that can be executed in the game.

\textbf{Movement}: The action \verb|a_move(Person p, ManArea to)| only describes a destination to go to and not the path to take. 
A shortest path algorithm should be used to find a path that the person can walk until it is at the destination. 
The path also needs to be translated into individual keypresses on W,A,S and D for the character's movement in the game.

\textbf{Arranging, Picking Up and Dropping}: All of these actions require the pressing of the space bar in the game.

\textbf{Chopping}: Chopping requires holding the CTRL key.

\textbf{Boiling and Frying}: These actions do not require any input. 
However, the cooking state should be monitored to avoid overcooking.



% Inserting new tasks into an existing plan is handled using the following procedure:
% The current state of the environment is saved to the Problem.
% For each partly executed task, a new method is created in the problem that only includes the not yet executed actions of the hierarchy.
% This method can only be used when exactly these conditions apply, therefore the methods receives the preconditions tied to this execution.
% Each variable used in these method is required to be the instance used in the current plan and they are also required to have the same value as in the current state.
% For tasks that are currently executing, \todo{Do not know how to handle}
% Then the new task is inserted as a new chronicle and the planning is started again.


\subsection{Robustness Heuristic}
\label{sec:approach-robustness}

The robustness heuristic introduces a plan selection strategy that more likely chooses plans where the addition of new tasks in the plan is more likely to succeed.
Robustness is generally defined as follows.

\begin{definition}[Robustness]
    Robustness is the ability of a system to withstand stresses, pressures, perturbations, unpredictable changes, or variations in its operating environment without loss of functionality.
    A system that is designed to perform functionality in an expected environment is \emph{robust} if it is able to maintain its functionality under a set of incidences. \citep{barberRobustnessStabilityRecoverability2015}
\end{definition}

As also mentioned in \cite{barberRobustnessStabilityRecoverability2015}, the concrete "formalization depends on the system, on its expected functionality and on the specific set of incidences to be confronted".
In considerations of robustness in planning \citep{lundRobustExecutionProbabilistic2017}, the incidences are perturbations in the start and end time points of actions.
In a setting with static controllability, this leads to the most robust plans being ones that include as much margin between actions as possible.
% They introduce the Dynamic Robust Execution Algorithm for settings with dynamic controllability, which actively monitors the changes of time points.

In our case, controllability is mostly static, as we only replan on the arrival of new tasks.
However, we allow delays for action time points, during planning or while executing.
When adding new tasks during the execution, it is not beneficial to have large margins between the tasks.
Therefore, the robustness with respect to adding new tasks is determined by how likely it is that the addition of a new task is possible.

Two cases must be considered: All decomposed actions of the added task will happen after the end of the current plan, or the decomposed actions are at least partially executed during the current plan.
In the first case, the success of adding the new task is more likely when the current plan has a shorter makespan.
In the other case, the plan must be changed substantially.
Some existing actions must be pushed back, while the deadline for those tasks must still be fulfilled.
This works best when there are fewer dependencies between actions, and when the makespan is shorter.

We use perturbations directly as a metric for the robustness of a plan, similar to \cite{wehnerRobustVsFast2023}.
In our case, a perturbation is the delay of the start point of an action.
While the end time point of an action may also be delayed, that is not possible due to the insertion of a new task, but due to a delay in the execution.
Additionally, the end time point is automatically delayed when the start time point is delayed.

\begin{definition}[Delay Perturbation]
    A chronicle $\phi_1 = (\pi_1,\mathcal{F}_1,\mathcal{C}_1)$ can be changed into a chronicle $\phi_2 = (\pi_2,\mathcal{F}_2,\mathcal{C}_2)$ with a delay perturbation on an action $a \in \pi_1$ by an amount $x$ denoted as $\phi_1 \xrightarrow{a,x}_P \phi_2$ by the addition of a temporal constraint as follows, where $t^a_{start}$ is the starting time point of action $a$, $t^p_{start}$ is the starting time point of the temporal HTN Planning Problem and $mindelay(\phi_1,t^p_{start},t^a_{start})$ is the minimum delay between $t^p_{start}$ and $t^a_{start}$ in $\phi_1$.
    \begin{align*}
        \pi_2 \leftarrow & \pi_1 \\
        \mathcal{F}_2 \leftarrow & \mathcal{F}_1 \\
        \mathcal{C}_2 \leftarrow & \mathcal{C}_1 \cup \{t^p_{start} + (mindelay(\phi_1,t^p_{start},t^a_{start}) + x) \leq t^a_{start}\} \\
    \end{align*}
\end{definition}

% This definition considers all actions in a plan rigid, which is a common requirement in several application areas of planning.
% A plan that has been generated cannot be changed later, and some resources may also depend on the rigidness of the planned actions. 
% This makes the most robust plans always include padding between the individual actions.

% In this context that definition still holds, however the assumptions are different.
% Actions in this context may be delayed until the final deadline is missed.
% These delays may come from the insertion of new tasks into the existing plan.
% Therefore the actions in the plan are not rigid and padding does not make the plan more robust.
% Instead the robustness is calculated using pertubations similarly to the robustness in QCNs.

A new robustness heuristic is then introduced, that is used for node selection during planning.
A heuristic in FAPE includes the two functions $g(\pi)$ and $h(\pi)$ as it uses the A* search algorithm for node selection.
$g(\pi)$ describes the current cost and $h(\pi)$ describes the remaining cost of the plan.
$h(\pi)$ can not be estimated for robustness and is therefore left at 0.

\begin{align}
    % \hat{\phi} = \underset{\phi \in \Phi}{\argmax} \textit{ count of perturbations possible on } \phi \\
    % \phi_1 \xrightarrow{a_1,x_1}_P \dots \xrightarrow{a_n,x_n}_P \phi_{n+1}  \\
    % g(\phi) = \textit{ count of perturbations possible on } \phi \\
    g(\phi) &= \begin{cases}
        0 &\text{if } inconsistent(\phi) \\
        1 + g(\phi \xrightarrow{a,x}_P \phi') &\text{otherwise}
    \end{cases} \label{eq:approach-g-optimal}\\
    h(\phi) &= 0
\end{align}

In Equation \ref{eq:approach-g-optimal}, $a$ and $x$ are arbitrarily chosen, to get the most representative outcome.
As it is infeasible to calculate this representative outcome, $a$ and $x$ are chosen randomly in practice, with $a$ being a randomly chosen action in $\pi$ and $x$ being a random variable using a half-normal distribution.
The distribution variance is chosen as the minimum delay between the start of the action and the end of the plan.
Additionally, $x$ is at least $1$, as else there would not be a perturbation.
We introduce the notion of $\hat{g}(\phi,m)$ to capture the effect of $m$ random delay perturbations.

\begin{align}
    a &\sim \text{randomly choosen action} \in \pi\\
    x &\sim  1 + |\mathcal{N}(0,mindelay(\phi_1,t^a_{start},t^p_{end}))| \\
    \hat{g}(\phi,m) &= \begin{cases}
        0 &\text{if } inconsistent(\phi) \lor m = 0 \\
        1 + \hat{g}(\phi \xrightarrow{A,x}_P \phi', m - 1) &\text{otherwise}
    \end{cases}
\end{align}

The arithmetic mean over a fixed amount of perturbations $m$ and a fixed number of repetitions $n$ is used as an approximation for $g(\phi)$.
This heuristic can then be included during planning.

\begin{align}
    g(\phi) \approx \frac{1}{n} \sum_{i=1}^{n} \hat{g}(\phi,m)
\end{align}

\subsection{Preparation insertion}
\label{sec:approach-preparation}

Preparing parts of a meal is a common strategy in restaurants to handle high loads.
Due to the nature of the hierarchical plan, the essential subtasks for a task can be gathered.
For instance, a salad requires that lettuce be chopped.  
Lettuce can then be chopped when some cook has downtime in a plan.
Then, when an order for a salad is received, the lettuce only needs to be put on a plate and served.
However, the preparations should remain within the bounds of the current plan.
Otherwise, an unlimited amount of preparations could be inserted, which would first block the Acting Engine from receiving any new tasks and second would correspond to a restaurant that prepares all of the available ingredients even when there are only a few orders.

\begin{algorithm}
    \caption{PREPARATIONS: Generation of possible preparations}
    \label{alg:methodology:preparations}
    \KwIn{$\phi' = \langle \pi,\mathcal{F},\mathcal{C} \rangle$; $\mathcal{T}_p$}
    \KwOut{$T_p$}
    $T_p \leftarrow \emptyset$\;
    \ForEach{$\tau \in$ $T_p$}{
        \ForEach{$\text{action template } A \text{ for } \tau$}{
            \ForEach{$\tau_s \in subtasks(A)$}{
                \If{$parameters(\tau_s) \nsubseteq parameters(\tau)$}{
                    \ForEach{$t_p \in \text{temporally qualified ground instances  of } \tau_s, t_p \notin \pi$}{
                        $T_d \leftarrow dependencies(A,t_p)$\;
                        \If{$T_d \neq \varnothing$}{
                            \If{all $T_d$ executed} {
                                $T_p \leftarrow T_p + \{t_p\}$
                            }
                        }
                        \Else{
                            $T_p \leftarrow T_p + \{t_p\}$
                        }
                    }
                }
            }
        }
    }
    \Return{$T_p$}
\end{algorithm}

The generation of potentially preparable tasks is shown in Algorithm \ref{alg:methodology:preparations}.
It receives a list of potential task symbols $\mathcal{T}_p$, in our case the potential orders that may be received through the stream of tasks.
$\mathcal{T}_p$ may be known at the start but could be changed during the execution.
For each $\tau_p \in \mathcal{T}_p$ the possible subtasks are gathered through all possible action templates.
Subtasks that do not require any of the parameters of $\tau_p$ are independent of the individual order and thus potential subjects for preparation.
A subtask may require that one or more previous tasks have been executed first.
Those previous tasks have to be executed with the matching arguments before this task is subject to preparation.
The parameters for the preparable tasks have to be ground and there cannot exist another task with the same parameters in $\pi$.
Otherwise, a preparation could be added multiple times to a plan.
It is however allowed that the same task is present multiple times in the result of the algorithm.
Knowing how often a specific preparation is included can be helpful when choosing a preparation.

To be able to use a preparation later, tasks need to have one possible decomposition that is fulfilled if all postconditions are met.
Otherwise, the prepared instances could not be used in future submitted tasks due to the hierarchical decomposition.


Planning with preparations is done as depicted in Algorithm \ref{alg:methodology:prep-planning}.
When a plan has been found for a problem, possible preparations are generated.
One preparation is nondeterministically chosen to be included in the current chronicle and added as a temporally qualified task $\langle[t_{current}, mindelay(\phi,t^p_{start}, t^p_{end})] \tau \rangle$.
Planning is continued with the modified chronicle.
This procedure is repeated recursively until no plan is found.
Then the last valid plan is returned.

\begin{algorithm}
    \caption{PrepPSP: Planning with adding preparations}
    \label{alg:methodology:prep-planning}
    \KwIn{$P = \langle \Sigma,\phi \rangle$; $\mathcal{T}_p$}
    \KwOut{$\phi'$}
    $\phi' \leftarrow PSP(P)$\;
    \If{$\phi' =$ FAIL}{
        \Return{FAIL}
    }
    \Else{
        $T_p \leftarrow PREPARATIONS(\phi', \mathcal{T}_p)$\;
        nondeterministically choose $t_p \in T_p$\;
        $\phi' \xrightarrow{t_p}_I \phi''$\;
        $\phi'' \leftarrow PrepPSP(\langle \Sigma,\phi'' \rangle,\mathcal{T}_p)$\;
        \If{$\phi'' =$ FAIL}{\Return{$\phi'$}}
        \Else{\Return{$\phi''$}}
    }
\end{algorithm}

The preparation insertion is similar to action insertion.
While action insertion is used to support goals or preconditions of tasks using generative planning instead of HTN planning, preparation insertion supports possible future tasks.
The properties of preparation insertion vary significantly compared to task insertion.

We propose several concrete implementations of the non-deterministic choose method in algorithm \ref{alg:methodology:prep-planning}.
We call these implementations preparation selection strategies.

\begin{itemize}
  \item A random selection can be used as an approximation.
    The random selection gives preparations that are present multiple times in $T_p$ a higher likelihood.
  \item A greedy approach can be used to insert all possible preparations and then choose the best resulting plan.
  \item The time and resources required for a preparation task can be used to find the best combination of tasks to insert.
  The time and resource usage should be calculated as a static analysis before planning.
  \item Only the most common preparations are used.
    This prevents unnecessary further processing and it is unlikely that 
  \item A statistical or learning model of the environment can be used to predict the most likely tasks.
    Then the preparations can be chosen based on the likelihood of being necessary.
  \item Further metrics can be included based on the domain, like e.g. the storage life of ingredients after being prepared.
\end{itemize}
